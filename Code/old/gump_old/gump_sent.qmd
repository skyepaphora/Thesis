# Setup

```{r packages}
# Code ------------
library(multitaper) # spec.mtm, etc.
library(pbapply)    # Progress bar for apply() functions
library(itsmr)      # Time series stuff, used here for ARMA
library(nleqslv)    # Stupidly named nonlinear solving package
library(nloptr)     # A more flexible nonlinear solver

# Presentation ----
library(kableExtra) # Nice Tables
library(animation)  # For creating gifs
library(fields)     # Supplement image plots: legends, better colour schema

# Other -----------
options(digits = 10)
```

```{r load_data}
# Data ----
load("~/Research/PhD_Thesis/Data/GUMP_pbc/3-Eyed___B200_sd1___mini.RData")
# load("~/Research/PhD_Thesis/Data/GUMP_pbc/butterfly___B200_sd1___mini.RData")


# Simple naming for TRUE unknowns (TFS and vectors) ----
SX  <- info$tru$SX
SX1 <- info$tru$SX.1
SX2 <- info$tru$SX.2
g1  <- info$tru$gt.1
g2  <- info$tru$gt.2
S1  <- info$tru$SY.1
S2  <- info$tru$SY.2
```

## Partitioning & (de)Construction

```{r partitioning}
# Naming
abcd <- LETTERS[1:4]
varnames <- sapply(c("g1.","g2.","S1.","S2."), function(z){paste0(z,abcd)})

# Cell definitions ----
NN <- list(A = (0*N/4 +1):(1*N/4), 
           B = (1*N/4 +1):(2*N/4),
           C = (2*N/4 +1):(3*N/4),
           D = (3*N/4 +1):(4*N/4))

MM <- list(A = floor(0*NF/4 +1):floor(1*NF/4),
           B = floor(1*NF/4 +1):floor(2*NF/4), 
           C = floor(2*NF/4 +1):floor(3*NF/4), 
           D = floor(3*NF/4 +1):ceiling(4*NF/4))
```

```{r get16_reconstruct}
# Function: Sum over letterboxes and Pillarboxes, given component vecs
get.16 <- function(G1,G2,s1,s2){
  blocks <- c()
  for(j in 1:4){
    blocks[j]    <- sum(G1[NN[[j]] ])
    blocks[j+4]  <- sum(G2[NN[[j]] ])
    blocks[j+8]  <- sum(s1[MM[[j]] ])
    blocks[j+12] <- sum(s2[MM[[j]] ])
  }
  names(blocks)  <- varnames
  return(blocks)
}

# Function: Create SX, given component vecs
reconstruct <- function(G1,G2,s1,s2){
  return(outer(G1,s1) + outer(G2,s2))
}
```

```{r true16}
# 16 true Unknowns
unknowns.true <- get.16(g1,g2,S1,S2)
```

# SVD

```{r svd}
# Choose a TFS/Spectrogram
SX <- info$tru$SX                      # True TFS
# SX <- t(pbc$bc1$mean)                # 1-BC spectrogram
# SX <- t(pbc$bc2$mean)                # 2-BC spectrogram
# SX <- SX + rnorm(length(SX), 0, 2)   # Noisy true TFS

# Perform SVD
SX.svd <- svd((SX))

# Reconstruct SX and its UMP components ---- via UDV^T
SX.hat  <- SX.svd$u %*% diag(SX.svd$d) %*% t(SX.svd$v)
SX1.hat <- outer(SX.svd$u[,1]*sqrt(SX.svd$d[1]),(SX.svd$v[,1]*sqrt(SX.svd$d[1])))
SX2.hat <- outer(SX.svd$u[,2]*sqrt(SX.svd$d[2]),(SX.svd$v[,2]*sqrt(SX.svd$d[2])))

# Sanity Check ----
max(abs(SX  - SX.hat ))
max(abs(SX1 - SX1.hat))
max(abs(SX2 - SX2.hat))

# Optional SVD translation Function ----
trans <- function(z, buff = 0.1){ z - min(z) + buff }
trans <- function(z){z} # easy on/off
```

```{r svd_3Dplots_BEWARE}
par(mfrow = c(3,2))
limo <- range(SX1,SX2,SX,SX1.hat,SX2.hat,SX.hat)
image.plot(SX1, zlim = limo, main = "SX1"); image.plot(SX1.hat, zlim = limo, main = "SX1 hat")
image.plot(SX2, zlim = limo, main = "SX2"); image.plot(SX2.hat, zlim = limo, main = "SX2 hat")
image.plot(SX , zlim = limo, main = "SX" ); image.plot(SX.hat , zlim = limo, main = "SX hat")
```

```{r svd_compvecs}
# L1 and L2                # scale by sqrt of singular values
g1.svd <- trans(SX.svd$u[,1]*sqrt(SX.svd$d[1]))
g2.svd <- trans(SX.svd$u[,2]*sqrt(SX.svd$d[2]))

# R1 and R2                # scale by sqrt of singular values
S1.svd <- trans(SX.svd$v[,1]*sqrt(SX.svd$d[1]))
S2.svd <- trans(SX.svd$v[,2]*sqrt(SX.svd$d[2]))
```

```{r svd_plot}
# Prep plot ----
par(mfrow = c(4,2))
lim.g <- range(g1,g2,g1.svd,g2.svd)
lim.S <- range(S1,S2,S1.svd,S2.svd)
zero  <- function(){abline(h=0,lty=2)}

# Comp vecs, SVD estimates ----
plot(g1, ylim = lim.g); zero();    plot(g1.svd, ylim = lim.g); zero()
plot(g2, ylim = lim.g); zero();    plot(g2.svd, ylim = lim.g); zero()
plot(S1, ylim = lim.S); zero();    plot(S1.svd, ylim = lim.S); zero()
plot(S2, ylim = lim.S); zero();    plot(S2.svd, ylim = lim.S); zero()
```


# Prep Optimizers

```{r}
# Starting points ----
test.0   <- unknowns.true
test.1   <- unknowns.true + rnorm(16)
test.svd <- get.16(g1.svd,g2.svd,S1.svd,S2.svd)
```

```{r cobyla_setup}
# Parameters 
U  <- lapply(MM, function(x){rowSums(SX[,x])}) # rowsums partitioned by letterbox
V  <- lapply(NN, function(x){colSums(SX[x,])}) # colsums partitioned by pillarbox

# Objective function 0 (archaic): only use if you REALLY need a gradient
fn.0 <- function(x) {
  list(
    "objective" 
          #              g1     S1               g2     S2
          = (sum(outer(x[1:4],x[9:12]) + outer(x[5:8],x[13:16]) ) - Uhat)^2,
    "gradient" 
          = c(sum(x[ 9:12]),sum(x[ 9:12]),sum(x[ 9:12]),sum(x[ 9:12]), # g1
              sum(x[13:16]),sum(x[13:16]),sum(x[13:16]),sum(x[13:16]), # g2
              sum(x[ 1: 4]),sum(x[ 1: 4]),sum(x[ 1: 4]),sum(x[ 1: 4]), # S1
              sum(x[ 5: 8]),sum(x[ 5: 8]),sum(x[ 5: 8]),sum(x[ 5: 8])) # S2
    )
}

# Objective function 1: smallest max error (Full TFS) 
fn.1 <- function(x){
  
  g1.hat <- (U$A*x[14]-U$B*x[13]) / (x[ 9]*x[14]-x[10]*x[13])  
  g2.hat <- (U$A*x[10]-U$B*x[ 9]) / (x[13]*x[10]-x[14]*x[ 9])  
  S1.hat <- (V$A*x[ 6]-V$B*x[ 5]) / (x[ 1]*x[ 6]-x[ 2]*x[ 5])  
  S2.hat <- (V$A*x[ 2]-V$B*x[ 1]) / (x[ 5]*x[ 2]-x[ 6]*x[ 1]) 
  
  max(abs(reconstruct(g1.hat,g2.hat,S1.hat,S2.hat) - t(SX)))
}

# Objective function 2: smallest residual sum of squares
fn.2 <- function(x){
  
  g1.hat <- (U$A*x[14]-U$B*x[13]) / (x[ 9]*x[14]-x[10]*x[13])  
  g2.hat <- (U$A*x[10]-U$B*x[ 9]) / (x[13]*x[10]-x[14]*x[ 9])  
  S1.hat <- (V$A*x[ 6]-V$B*x[ 5]) / (x[ 1]*x[ 6]-x[ 2]*x[ 5])  
  S2.hat <- (V$A*x[ 2]-V$B*x[ 1]) / (x[ 5]*x[ 2]-x[ 6]*x[ 1]) 
  
  lmod <- lm(c(SX.hat) ~ c(outer(g1.hat,S1.hat)) + c(outer(g2.hat,S2.hat)))

  deviance(lmod)
  
  }

# Inequality constraints
hin.1 <- function(x){ c(
  max( -((U$A*x[14]-U$B*x[13]) / (x[ 9]*x[14]-x[10]*x[13])) ), 
  max( -((U$A*x[10]-U$B*x[ 9]) / (x[13]*x[10]-x[14]*x[ 9])) ), 
  max( -((V$A*x[ 6]-V$B*x[ 5]) / (x[ 1]*x[ 6]-x[ 2]*x[ 5])) ), 
  max( -((V$A*x[ 2]-V$B*x[ 1]) / (x[ 5]*x[ 2]-x[ 6]*x[ 1])) ))
}

# Upper bounds
top <- c( 
  unlist(rep( lapply(NN, FUN = function(z){max(colSums(SX[z, ]))}),  2)),
  unlist(rep( lapply(MM, FUN = function(z){max(rowSums(SX[ ,z]))}),  2))
  )
names(top) <- varnames

# Step tolerance
tol <- 1e-6
```

# Cobyla: Constrained Optimization by Linear Approximations (gradient free)

```{r cobyla_RUN}
# Initialize and RUN ----
x0 <- test.svd
cob <- cobyla(
         x0  = x0,                        # Start vector
         fn  = fn.2,                      # Objective function
         hin = hin.1,                     # Inequality constraints
         lower = rep(min(0,x0),16),       # vector of output bounds
         upper = top,
         nl.info = TRUE,                  # save optimization info
         deprecatedBehavior = FALSE,      # flip Jac. function (required)
         control = list(xtol_rel = tol,   # stop when step gets this small
                        maxeval = 1000)
         )

# Store results (a couple of times, since I'll overwrite "x" later)
x <- x.cob <- cob$par
names(x) <- names(x.cob) <- varnames
```

```{r solve_AB}
get.compvecs <- function(X){
  # Solve for time functions
  g1.hat <- (U$A*X["S2.B"]-U$B*X["S2.A"]) / (X["S1.A"]*X["S2.B"]-X["S1.B"]*X["S2.A"])
  g2.hat <- (U$A*X["S1.B"]-U$B*X["S1.A"]) / (X["S2.A"]*X["S1.B"]-X["S2.B"]*X["S1.A"])
    
  # Solve for freq functions
  S1.hat <- (V$A*X["g2.B"]-V$B*X["g2.A"]) / (X["g1.A"]*X["g2.B"]-X["g1.B"]*X["g2.A"])
  S2.hat <- (V$A*X["g1.B"]-V$B*X["g1.A"]) / (X["g2.A"]*X["g1.B"]-X["g2.B"]*X["g1.A"])
  
  return(list(g1 = g1.hat, g2 = g2.hat, S1 = S1.hat, S2 = S2.hat))
}

compvecs <- get.compvecs(x)
g1.hat <- compvecs$g1;  S1.hat <- compvecs$S1
g2.hat <- compvecs$g2;  S2.hat <- compvecs$S2
```

```{r solve_CD}
# # You can use the other pillar/letterboxes if you want, by the way.
# # I'm commenting this chunk out in case you click "run all chunks above," later.
# 
# # Solve for time functions
# g1.hat <- (U$A*x["S2.D"]-U$B*x["S2.C"]) / (x["S1.C"]*x["S2.D"]-x["S1.D"]*x["S2.C"])
# g2.hat <- (U$A*x["S1.D"]-U$B*x["S1.C"]) / (x["S2.C"]*x["S1.D"]-x["S2.D"]*x["S1.C"])
#   
# # Solve for freq functions
# S1.hat <- (V$A*x["g2.D"]-V$B*x["g2.C"]) / (x["g1.C"]*x["g2.D"]-x["g1.D"]*x["g2.C"])
# S2.hat <- (V$A*x["g1.D"]-V$B*x["g1.C"]) / (x["g2.C"]*x["g1.D"]-x["g2.D"]*x["g1.C"])
```

## Plotting Cobyla's Component Vectors

```{r cobPlot_setup}
# Optional normalization function 
no <- function(z){z/max(abs(z))}
no <- function(x){x}  # easy on/off

# prep plots ----
par(mfrow = c(2,2), mar = c(4,4,2,1))
lim <- list(range(0, no(g1), no(g1.hat), no(g1.svd)), 
            range(0, no(g2), no(g2.hat), no(g2.svd)),
            range(0, no(S1), no(S1.hat), no(S1.svd)), 
            range(0, no(S2), no(S2.hat), no(S2.svd)))
lim <- list(range(lim),range(lim),range(lim),range(lim)) # easy on/off: common scale
```

```{r cobPlot_RUN}
# Compare Cobyla estimates, SVD estimates, and true compvecs ----
plot(t, no(g1),
     main = "g1 estimate (cobyla)", ylim = lim[[1]], type = "l")
        abline(h=0, lty = 2, col = "grey50")
        lines(t, no(g2)    , col = "grey77")
        lines(t, no(g1.svd), col = "dodgerblue")
        lines(t, no(g1.hat), col = "red", lwd = 2, lty = 2)
plot(t, no(g2),
     main = "g2 estimate (cobyla)", ylim = lim[[2]], type = "l")
        abline(h=0, lty = 2, col = "grey50")
        lines(t, no(g1)    , col = "grey77")
        lines(t, no(g2.svd), col = "dodgerblue")
        lines(t, no(g2.hat), col = "red", lwd = 2, lty = 2)
plot(f, no(S1),
     main = "S1 estimate (cobyla)", ylim = lim[[3]], type = "l")
        abline(h=0, lty = 2, col = "grey50")
        lines(f, no(S2)    , col = "grey77")
        lines(f, no(S1.svd), col = "dodgerblue")
        lines(f, no(S1.hat), col = "red", lwd = 2, lty = 2)
plot(f, no(S2),
     main = "S2 estimate (cobyla)", ylim = lim[[4]], type = "l")
        abline(h=0, lty = 2, col = "grey50")
        lines(f, no(S1)    , col = "grey77")
        lines(f, no(S2.svd), col = "dodgerblue")
        lines(f, no(S2.hat), col = "red", lwd = 2, lty = 2)
```

## 3D Cobyla plots

```{r store_sgrams}
# Get SX constructed from cobyla output, store and check errors
SX.hat <- reconstruct(no(g1.hat),no(g2.hat),no(S1.hat),no(S2.hat))
SX.no  <- reconstruct(no(g1),no(g2),no(S1),no(S2)) # in case 
SX.err <- abs(SX.hat - SX.no)

range(SX.err)
```

```{r plot_sgrams}
par(mfrow = c(3,1), mar = c(4,4,2,1))
zlims <- range(0, SX.hat, SX.no)
zlimo <- range(0, SX.err)
zlimo <- zlims # easy on/off for scaling error plot

# *sometimes* this does pretty well using fn.2 as the objective function...
# ONLY IF: you normalize everything [toggle no() from previously]
image.plot(f,t, t(SX.hat), zlim = zlims); mtext("estimate")
image.plot(f,t, t(SX.no) , zlim = zlims); mtext("TRUE")
image.plot(f,t, t(SX.err), zlim = zlimo); mtext("Absolute error plot")
```


# StoGO

```{r}
# Initialize and RUN
x0 <- test.svd

opts <- list("algorithm"   = "NLOPT_GD_STOGO",
             "xtol_rel"    = 1.0e-7,
             "maxeval"     = 2000,
             "print_level" = 0)

stob <- nloptr(x0 = x0,
             eval_f = fn.0,     # I DARE you to find the gradient of the others
             # lb = rep(0,16),
             # ub = top,
             opts = opts
)

# Store results (a couple of times, since I'll overwrite "x" later)
x <- x.stob <- stob$par
names(x) <- names(x.stob) <- varnames
```

```{r solve_AB}
# Get component vectors
compvecs <- get.compvecs(x)
g1.hat <- compvecs$g1;  S1.hat <- compvecs$S1
g2.hat <- compvecs$g2;  S2.hat <- compvecs$S2
```

## Plotting StoGO's Component Vectors

```{r stobPlot_setup}
# Optional normalization function 
no <- function(z){z/max(abs(z))}
no <- function(x){x}  # easy on/off

# prep plots ----
par(mfrow = c(2,2), mar = c(4,4,2,1))
lim <- list(range(0, no(g1), no(g1.hat), no(g1.svd)), 
            range(0, no(g2), no(g2.hat), no(g2.svd)),
            range(0, no(S1), no(S1.hat), no(S1.svd)), 
            range(0, no(S2), no(S2.hat), no(S2.svd)))
lim <- list(range(lim),range(lim),range(lim),range(lim)) # easy on/off: common scale
```

```{r stobPlot_RUN}
# Compare StoGO estimates, SVD estimates, and true compvecs ----
plot(t, no(g1),
     main = "g1 estimate (StoGO)", ylim = lim[[1]], type = "l")
        abline(h=0, lty = 2, col = "grey50")
        lines(t, no(g2)    , col = "grey77")
        lines(t, no(g1.svd), col = "dodgerblue")
        lines(t, no(g1.hat), col = "red", lwd = 2, lty = 2)
plot(t, no(g2),
     main = "g2 estimate (StoGO)", ylim = lim[[2]], type = "l")
        abline(h=0, lty = 2, col = "grey50")
        lines(t, no(g1)    , col = "grey77")
        lines(t, no(g2.svd), col = "dodgerblue")
        lines(t, no(g2.hat), col = "red", lwd = 2, lty = 2)
plot(f, no(S1),
     main = "S1 estimate (StoGO)", ylim = lim[[3]], type = "l")
        abline(h=0, lty = 2, col = "grey50")
        lines(f, no(S2)    , col = "grey77")
        lines(f, no(S1.svd), col = "dodgerblue")
        lines(f, no(S1.hat), col = "red", lwd = 2, lty = 2)
plot(f, no(S2),
     main = "S2 estimate (StoGO)", ylim = lim[[4]], type = "l")
        abline(h=0, lty = 2, col = "grey50")
        lines(f, no(S1)    , col = "grey77")
        lines(f, no(S2.svd), col = "dodgerblue")
        lines(f, no(S2.hat), col = "red", lwd = 2, lty = 2)
```

## 3D StoGO plots

```{r store_sgrams}
# Get SX constructed from StoGO output, store and check errors
SX.hat <- reconstruct(no(g1.hat),no(g2.hat),no(S1.hat),no(S2.hat))
SX.no  <- reconstruct(no(g1),no(g2),no(S1),no(S2)) # in case 
SX.err <- abs(SX.hat - SX.no)

range(SX.err)
```

```{r plot_sgrams}
par(mfrow = c(3,1), mar = c(4,4,2,1))
zlims <- range(0, SX.hat, SX.no)
zlimo <- range(0, SX.err)
zlimo <- zlims # easy on/off for scaling error plot

image.plot(f,t, t(SX.hat), zlim = zlims); mtext("estimate")
image.plot(f,t, t(SX.no) , zlim = zlims); mtext("TRUE")
image.plot(f,t, t(SX.err), zlim = zlimo); mtext("Absolute error plot")
```


# Multi-level Single-linkage (WARNING: takes 2 freaking hours to run for fn.2)
This uses randomized multiple startpoints and doesn't require gradients.
Per documentation: 
  mlsl() function only works with BFGS (Broyden-Fletcher-Goldfarb-Shanno) algorithm
  (but that... does? use? gradients?)
There seem to be multiple ways to implement though, such as directly through nloptr

```{r MLSL_V1}
# Initialize and RUN
x0 <- test.svd

gc()
local_opts <- list(xtol_rel = 1e-10, maxeval = 100)
mob <- mlsl(x0 = x0,
            fn = fn.2, # you've been warned
            lower = rep(min(0, x0),16),
            upper = top,
            nl.info = TRUE)

# Store results (a couple of times, since I'll overwrite "x" later)
x <- x.mob <- mob$par
names(x) <- names(x.mob) <- varnames
```

This version uses the rectangular division algorithm (actually gradient free)
AND IT DOESN't TAKE 2 HOURS
but it doesn't actually seem to do anything

```{r MLSL_V2}
local_opts <- list("algorithm" = "NLOPT_GN_DIRECT",
                   "xtol_rel"  = 1.0e-7)
opts <- list("algorithm"   = "NLOPT_GN_MLSL",
             "xtol_rel"    = 1.0e-7,
             "maxeval"     = 2000,
             "local_opts"  = local_opts,
             "print_level" = 0)

mob2 <- nloptr(x0 = test.svd,
             eval_f = fn.2,
             # lb = rep(0,16),
             # ub = top,
             opts = opts
)
# Store results (a couple of times, since I'll overwrite "x" later)
x <- x.mob2 <- mob2$solution
names(x) <- names(x.mob) <- varnames
```

```{r solve_AB}
# Get component vectors
compvecs <- get.compvecs(x)
g1.hat <- compvecs$g1;  S1.hat <- compvecs$S1
g2.hat <- compvecs$g2;  S2.hat <- compvecs$S2
```

## Plotting MLSL's Component Vectors

```{r mobPlot_setup}
# Optional normalization function 
no <- function(z){z/max(abs(z))}
no <- function(x){x}  # easy on/off

# prep plots ----
par(mfrow = c(2,2), mar = c(4,4,2,1))
lim <- list(range(0, no(g1), no(g1.hat), no(g1.svd)), 
            range(0, no(g2), no(g2.hat), no(g2.svd)),
            range(0, no(S1), no(S1.hat), no(S1.svd)), 
            range(0, no(S2), no(S2.hat), no(S2.svd)))
lim <- list(range(lim),range(lim),range(lim),range(lim)) # easy on/off: common scale
```

```{r mobPlot_RUN}
# Compare MLSL estimates, SVD estimates, and true compvecs ----
plot(t, no(g1),
     main = "g1 estimate (MLSL)", ylim = lim[[1]], type = "l")
        abline(h=0, lty = 2, col = "grey50")
        lines(t, no(g2)    , col = "grey77")
        lines(t, no(g1.svd), col = "dodgerblue")
        lines(t, no(g1.hat), col = "red", lwd = 2, lty = 2)
plot(t, no(g2),
     main = "g2 estimate (MLSL)", ylim = lim[[2]], type = "l")
        abline(h=0, lty = 2, col = "grey50")
        lines(t, no(g1)    , col = "grey77")
        lines(t, no(g2.svd), col = "dodgerblue")
        lines(t, no(g2.hat), col = "red", lwd = 2, lty = 2)
plot(f, no(S1),
     main = "S1 estimate (MLSL)", ylim = lim[[3]], type = "l")
        abline(h=0, lty = 2, col = "grey50")
        lines(f, no(S2)    , col = "grey77")
        lines(f, no(S1.svd), col = "dodgerblue")
        lines(f, no(S1.hat), col = "red", lwd = 2, lty = 2)
plot(f, no(S2),
     main = "S2 estimate (MLSL)", ylim = lim[[4]], type = "l")
        abline(h=0, lty = 2, col = "grey50")
        lines(f, no(S1)    , col = "grey77")
        lines(f, no(S2.svd), col = "dodgerblue")
        lines(f, no(S2.hat), col = "red", lwd = 2, lty = 2)
```

## 3D MLSL plots

```{r store_sgrams}
# Get SX constructed from MLSL output, store and check errors
SX.hat <- reconstruct(no(g1.hat),no(g2.hat),no(S1.hat),no(S2.hat))
SX.no  <- reconstruct(no(g1),no(g2),no(S1),no(S2)) # in case 
SX.err <- abs(SX.hat - SX.no)

range(SX.err)
```

```{r plot_sgrams}
par(mfrow = c(3,1), mar = c(4,4,2,1))
zlims <- range(0, SX.hat, SX.no)
zlimo <- range(0, SX.err)
zlimo <- zlims # easy on/off for scaling error plot

image.plot(f,t, t(SX.hat), zlim = zlims); mtext("estimate")
image.plot(f,t, t(SX.no) , zlim = zlims); mtext("TRUE")
image.plot(f,t, t(SX.err), zlim = zlimo); mtext("Absolute error plot")
```

# DIRECT  (no multistart)
Again, doesn't seem to go anywhere

```{r}
# Initialize and RUN
x0 <- test.svd

opts <- list("algorithm"   = "NLOPT_GN_DIRECT",
             "xtol_rel"    = 1.0e-7,
             "maxeval"     = 2000,
             "print_level" = 0)

dob <- nloptr(x0 = x0,
             eval_f = fn.2,     
             # lb = rep(0,16),
             # ub = top,
             opts = opts
)

# Store results (a couple of times, since I'll overwrite "x" later)
x <- x.dob <- dob$solution
names(x) <- names(x.dob) <- varnames
```

```{r solve_AB}
# Get component vectors
compvecs <- get.compvecs(x)
g1.hat <- compvecs$g1;  S1.hat <- compvecs$S1
g2.hat <- compvecs$g2;  S2.hat <- compvecs$S2
```

## Plotting DIRECT's Component Vectors
Again, doesn't seem to go anywhere. I just get back the SVDs.

```{r dobPlot_setup}
# Optional normalization function 
no <- function(z){z/max(abs(z))}
no <- function(x){x}  # easy on/off

# prep plots ----
par(mfrow = c(2,2), mar = c(4,4,2,1))
lim <- list(range(0, no(g1), no(g1.hat), no(g1.svd)), 
            range(0, no(g2), no(g2.hat), no(g2.svd)),
            range(0, no(S1), no(S1.hat), no(S1.svd)), 
            range(0, no(S2), no(S2.hat), no(S2.svd)))
lim <- list(range(lim),range(lim),range(lim),range(lim)) # easy on/off: common scale
```

```{r dobPlot_RUN}
# Compare DIRECT estimates, SVD estimates, and true compvecs ----
plot(t, no(g1),
     main = "g1 estimate (DIRECT)", ylim = lim[[1]], type = "l")
        abline(h=0, lty = 2, col = "grey50")
        lines(t, no(g2)    , col = "grey77")
        lines(t, no(g1.svd), col = "dodgerblue")
        lines(t, no(g1.hat), col = "red", lwd = 2, lty = 2)
plot(t, no(g2),
     main = "g2 estimate (DIRECT)", ylim = lim[[2]], type = "l")
        abline(h=0, lty = 2, col = "grey50")
        lines(t, no(g1)    , col = "grey77")
        lines(t, no(g2.svd), col = "dodgerblue")
        lines(t, no(g2.hat), col = "red", lwd = 2, lty = 2)
plot(f, no(S1),
     main = "S1 estimate (DIRECT)", ylim = lim[[3]], type = "l")
        abline(h=0, lty = 2, col = "grey50")
        lines(f, no(S2)    , col = "grey77")
        lines(f, no(S1.svd), col = "dodgerblue")
        lines(f, no(S1.hat), col = "red", lwd = 2, lty = 2)
plot(f, no(S2),
     main = "S2 estimate (DIRECT)", ylim = lim[[4]], type = "l")
        abline(h=0, lty = 2, col = "grey50")
        lines(f, no(S1)    , col = "grey77")
        lines(f, no(S2.svd), col = "dodgerblue")
        lines(f, no(S2.hat), col = "red", lwd = 2, lty = 2)
```

## 3D DIRECT plots

```{r store_sgrams}
# Get SX constructed from DIRECT output, store and check errors
SX.hat <- reconstruct(no(g1.hat),no(g2.hat),no(S1.hat),no(S2.hat))
SX.no  <- reconstruct(no(g1),no(g2),no(S1),no(S2)) # in case 
SX.err <- abs(SX.hat - SX.no)

range(SX.err)
```

```{r plot_sgrams}
par(mfrow = c(3,1), mar = c(4,4,2,1))
zlims <- range(0, SX.hat, SX.no)
zlimo <- range(0, SX.err)
zlimo <- zlims # easy on/off for scaling error plot

image.plot(f,t, t(SX.hat), zlim = zlims); mtext("estimate")
image.plot(f,t, t(SX.no) , zlim = zlims); mtext("TRUE")
image.plot(f,t, t(SX.err), zlim = zlimo); mtext("Absolute error plot")
```

